{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "import re\n",
    "import pymongo\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---main_bulk 5.0785639286 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "msg = {\"Message-ID\":'<13632441.1075857819209.JavaMail.evans@thyme>',\n",
    "\"Date\":'Wed, 30 Aug 2000 09:09:00 -0700 (PDT)',\n",
    "\"From\":'kevin.ruscitti@enron.com',\n",
    "\"To\":'ktruscitti@hotmail.com',\n",
    "\"Subject\":'Re: everything',\n",
    "\"X-From\":'Kevin Ruscitti',\n",
    "\"X-To\":'\"keith ruscitti\" <ktruscitti@hotmail.com> @ ENRON'}\n",
    "\n",
    "msg['body'] = \"\"\"\n",
    "Sounds great.  Moller's email address is Richard.J.Moller@marshmc.com.  I do \n",
    "not have anyone else's email,\n",
    "but Moller should be able to provide you with Coun's and Ricigiliano's.  Just \n",
    "ask him.Let me know if you need anything\n",
    "else.\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Kevin\n",
    "\"\"\"\n",
    "\n",
    "root_dir = \"/home/jovyan/work/dev/enron-playground/data/maildir/allen-p\"\n",
    "#root_dir = \"/home/jovyan/work/dev/enron-playground/data/maildir/giron-d/all_documents\"\n",
    "#root_dir =\"/home/jovyan/work/dev/enron-playground/data/maildir/lay-k/discussion_threads\"\n",
    "#print msg\n",
    "\n",
    "MongoClient = pymongo.MongoClient\n",
    "conn = MongoClient('mongo-enron', 27017)\n",
    "#use enron database\n",
    "db = conn['enron']\n",
    "messages = db.messages\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def get_file_list():\n",
    "    rtn = []\n",
    "    i=0\n",
    "    #rtn = [os.path.join(root, filename) for root, dirs, files in os.walk(root_dir, topdown=False) for filename in files ]\n",
    "    for root, dirs, files in os.walk(root_dir,topdown=False):\n",
    "        for filename in files:\n",
    "            if not filename.startswith(\".\"): \n",
    "                path = os.path.join(root,filename)\n",
    "                rtn.append(path)\n",
    "                i+=1\n",
    "                if i % batch_size == 0:\n",
    "                    print (\"%s - %s\" % (i, path) )\n",
    "    return rtn\n",
    "\n",
    "def get_msg_from_file(filename):\n",
    "    #extract email message from a file\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    rtn = email.message_from_string(contents)\n",
    "    return rtn\n",
    "\n",
    "def get_db_record_dict(msg, filename):\n",
    "    rtn=dict()\n",
    "    #these are the interesting fields to buid a schema\n",
    "    fields=['Message-ID', 'Date', 'From', 'To', 'Cc', 'Bcc', 'Subject','X-From', 'X-To', 'X-cc', 'X-bcc']\n",
    "\n",
    "    for field in fields:\n",
    "        if field in msg:\n",
    "            rtn[field.lower()] = msg[field].decode('ISO-8859-1').encode('utf-8')\n",
    "            #in the case of destination emails, create a nice array\n",
    "            if field in ('To', 'X-To', 'Cc', 'X-cc', 'Bcc', 'X-bcc'):\n",
    "                rtn[field.lower()] = [to_str.strip('\\n\\r\\t ') for to_str in rtn[field.lower()].split(\",\")]\n",
    "    \n",
    "    rtn['filename'] = filename\n",
    "    body = msg.get_payload()\n",
    "    rtn['body'] = body\n",
    "    return rtn\n",
    "\n",
    "def upsert_message(db_record):\n",
    "    #performs an upsert in order not to insert repeated emails\n",
    "    keyfields = ['from', 'to', 'subject', 'body', 'date']\n",
    "    key = {}\n",
    "    for keyfield in keyfields:\n",
    "        if keyfield in db_record:\n",
    "            key[keyfield] = db_record[keyfield]\n",
    "    object_id = messages.replace_one(key, db_record, True).upserted_id\n",
    "    #print object_id\n",
    "    \n",
    "def create_index():\n",
    "    keyfields = [('from',pymongo.ASCENDING), ('subject',pymongo.ASCENDING), ('date',pymongo.ASCENDING)]\n",
    "    messages.create_index(keyfields, unique=True)\n",
    "    \n",
    "    \n",
    "def insert_records(db_records):\n",
    "    object_ids = []\n",
    "    if len(db_records)>0:\n",
    "        try:\n",
    "            object_ids = messages.insert_many(db_records, ordered=False).inserted_ids\n",
    "        except pymongo.errors.BulkWriteError as e:\n",
    "            ##ignoring duplicates\n",
    "            print \"ignoring duplicates\"\n",
    "            other_errors = filter(lambda x: x['code'] != 11000, e.details['writeErrors'])\n",
    "            if len(other_errors):\n",
    "                print other_errors\n",
    "            pass\n",
    "\n",
    "        return object_ids\n",
    "\n",
    "def process_file_list_upsert(file_list):\n",
    "    for filename in file_list:\n",
    "        msg = get_msg_from_file(filename)\n",
    "        db_record = get_db_record_dict(msg)\n",
    "        upsert_message(db_record)\n",
    "        \n",
    "\n",
    "def process_file_list_bulk(file_list):\n",
    "    db_records=[]\n",
    "    create_index()\n",
    "    \n",
    "    for filename in file_list:\n",
    "        msg = get_msg_from_file(filename)\n",
    "        db_record = get_db_record_dict(msg, filename)\n",
    "        db_records.append(db_record)\n",
    "        if len(db_records) % batch_size == 0:\n",
    "            insert_records(db_records)\n",
    "            db_records=[]\n",
    "    \n",
    "    insert_records(db_records)\n",
    "        \n",
    "def main_upsert():\n",
    "    start_time = time.time()\n",
    "    file_list = get_file_list()\n",
    "    process_file_list_upsert(file_list)\n",
    "    print(\"---main_upsert %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    \n",
    "def main_bulk():\n",
    "    start_time = time.time()\n",
    "    file_list = get_file_list()\n",
    "    process_file_list_bulk(file_list)\n",
    "    print(\"---main_bulk %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "#main_upsert()\n",
    "main_bulk()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
